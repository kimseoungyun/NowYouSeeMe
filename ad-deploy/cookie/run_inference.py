#!/usr/bin/env python3
"""
run_inference.py
================
inference íŒŒì´í”„ë¼ì¸ wrapper ìŠ¤í¬ë¦½íŠ¸.
inference í´ë”ì˜ ê¸°ì¡´ main.pyë¥¼ subprocessë¡œ í˜¸ì¶œí•˜ê³ ,
ê²°ê³¼ë¥¼ TTS í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

inference í´ë”ì˜ ê¸°ì¡´ íŒŒì¼ë“¤ì€ ì „í˜€ ìˆ˜ì •í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

Usage:
    python run_inference.py --video_path /path/to/video.mp4 --output_dir /path/to/output --lang ko
    
Output:
    TTS í˜¸í™˜ JSON íŒŒì¼ (audio_descriptions í˜•ì‹)
"""

import sys
import os
import json
import argparse
import subprocess
import shutil
from pathlib import Path

# inference í´ë” ê²½ë¡œ
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(os.path.dirname(SCRIPT_DIR))
INFERENCE_DIR = os.path.join(PROJECT_ROOT, "inference")
INFERENCE_VENV_PYTHON = os.path.join(INFERENCE_DIR, "venv", "bin", "python")
INFERENCE_MAIN = os.path.join(INFERENCE_DIR, "main.py")


def translate_to_korean_simple(text):
    """
    ê°„ë‹¨í•œ ë²ˆì—­ í•¨ìˆ˜ (Google Translate API ì‚¬ìš©).
    ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” ë” ë‚˜ì€ ë²ˆì—­ APIë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    """
    try:
        from deep_translator import GoogleTranslator
        translator = GoogleTranslator(source='en', target='ko')
        return translator.translate(text)
    except ImportError:
        print("âš ï¸ deep_translator not installed. Install with: pip install deep-translator")
        return text
    except Exception as e:
        print(f"âš ï¸ Translation error: {e}")
        return text


def convert_to_tts_format(stage3_data, video_path, lang='en'):
    """
    stage3 ê²°ê³¼ë¥¼ TTS í˜¸í™˜ í˜•ì‹ (audio_descriptions)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Input format (stage3):
    [
        {
            "start_time": 0.0,
            "end_time": 3.94,
            "dialogue": "Hello, Walter.",
            "final_narrative": "Man A stands near the front car..."
        }
    ]
    
    Output format (TTS compatible):
    {
        "video_info": {...},
        "audio_descriptions": [
            {
                "id": 1,
                "start_time": 0.0,
                "end_time": 3.94,
                "duration_sec": 3.94,
                "description": "Man A stands near the front car..."
            }
        ]
    }
    """
    audio_descriptions = []
    
    for idx, item in enumerate(stage3_data):
        start_time = float(item.get('start_time', 0))
        end_time = float(item.get('end_time', 0))
        duration = end_time - start_time
        
        # final_narrative ë˜ëŠ” stage1_result ì‚¬ìš©
        description = item.get('final_narrative', '') or item.get('stage1_result', '')
        
        if not description:
            continue
        
        # í•œêµ­ì–´ ë²ˆì—­ (ì˜µì…˜)
        if lang == 'ko':
            description = translate_to_korean_simple(description)
            
        audio_descriptions.append({
            "id": idx + 1,
            "original_id": idx + 1,
            "start_time": start_time,
            "end_time": end_time,
            "duration_sec": round(duration, 3),
            "description": description,
            "dialogue": item.get('dialogue', ''),
            "is_split": False,
            "split_info": None
        })
    
    return {
        "video_info": {
            "source_file": os.path.basename(video_path),
            "language": lang,
            "total_segments": len(audio_descriptions)
        },
        "audio_descriptions": audio_descriptions
    }


def run_inference_pipeline(video_path, output_dir=None, lang='en', video_id=None):
    """
    inference íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    Args:
        video_path: ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ (ì ˆëŒ€ ê²½ë¡œ)
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        lang: ì¶œë ¥ ì–¸ì–´ ('en' ë˜ëŠ” 'ko')
        video_id: ë¹„ë””ì˜¤ ID (íŒŒì¼ëª… ìƒì„±ì— ì‚¬ìš©)
    
    Returns:
        dict: TTS í˜¸í™˜ í˜•ì‹ì˜ ê²°ê³¼
    """
    
    # ë¹„ë””ì˜¤ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    video_path = os.path.abspath(video_path)
    
    if not os.path.exists(video_path):
        raise FileNotFoundError(f"Video file not found: {video_path}")
    
    # output_dirì´ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ inference/output ì‚¬ìš©
    if output_dir is None:
        output_dir = os.path.join(INFERENCE_DIR, "output")
    
    os.makedirs(output_dir, exist_ok=True)
    
    print(f">> Inference Pipeline Starting...")
    print(f"   Video: {video_path}")
    print(f"   Output: {output_dir}")
    print(f"   Language: {lang}")
    
    # =====================================================
    # Step 1: inference/main.py ì‹¤í–‰
    # =====================================================
    # inference í´ë”ì˜ config.pyë¥¼ ì„ì‹œë¡œ ìˆ˜ì •í•˜ì§€ ì•Šê³ ,
    # í™˜ê²½ ë³€ìˆ˜ë¡œ ë¹„ë””ì˜¤ ê²½ë¡œë¥¼ ì „ë‹¬í•˜ëŠ” ë°©ì‹ì€ ì§€ì›ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ,
    # ë¹„ë””ì˜¤ íŒŒì¼ì„ inference í´ë”ë¡œ ë³µì‚¬í•˜ê±°ë‚˜ ì‹¬ë³¼ë¦­ ë§í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    # ë¹„ë””ì˜¤ íŒŒì¼ì´ inference í´ë”ì— ì—†ìœ¼ë©´ ì‹¬ë³¼ë¦­ ë§í¬ ìƒì„±
    video_basename = os.path.basename(video_path)
    inference_video_path = os.path.join(INFERENCE_DIR, video_basename)
    
    link_created = False
    if video_path != inference_video_path and not os.path.exists(inference_video_path):
        try:
            os.symlink(video_path, inference_video_path)
            link_created = True
            print(f"   Created symlink: {inference_video_path} -> {video_path}")
        except OSError as e:
            # ì‹¬ë³¼ë¦­ ë§í¬ ì‹¤íŒ¨ ì‹œ ë³µì‚¬
            print(f"   Symlink failed, copying video file...")
            shutil.copy2(video_path, inference_video_path)
            link_created = True
    
    # config.pyì˜ VIDEO_PATHë¥¼ ì„ì‹œë¡œ ìˆ˜ì •í•˜ëŠ” ëŒ€ì‹ ,
    # ë¹„ë””ì˜¤ íŒŒì¼ ì´ë¦„ì´ ì¼ì¹˜í•˜ë„ë¡ ì²˜ë¦¬
    # (ê¸°ì¡´ config.pyì˜ VIDEO_PATHì™€ ë‹¤ë¥¸ ê²½ìš°)
    
    # Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (inference í´ë”ì—ì„œ)
    # main.pyëŠ” config.pyì˜ VIDEO_PATHë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ,
    # ë³„ë„ ë˜í¼ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë§Œë“¤ì–´ configë¥¼ ë™ì ìœ¼ë¡œ ì„¤ì •
    
    wrapper_script = f'''
import sys
import os
sys.path.insert(0, "{INFERENCE_DIR}")
os.chdir("{INFERENCE_DIR}")

# config ëª¨ë“ˆì˜ VIDEO_PATHë¥¼ ë™ì ìœ¼ë¡œ ë³€ê²½
import config
config.VIDEO_PATH = "{inference_video_path}"
config.OUTPUT_DIR = "{output_dir}"
config.OUTPUT_JSON_PATH = os.path.join(config.OUTPUT_DIR, "final_ad_creation_output.json")
config.STAGE1_OUTPUT_JSON = os.path.join(config.OUTPUT_DIR, "stage1_narrative_output.json")
config.STAGE2_OUTPUT_JSON = os.path.join(config.OUTPUT_DIR, "stage2_final_output.json")
config.STAGE2_LOG_FILE = os.path.join(config.OUTPUT_DIR, "stage2_final_log.jsonl")
config.STAGE3_OUTPUT_JSON = os.path.join(config.OUTPUT_DIR, "stage3_final_narrative_refined.json")

# main ëª¨ë“ˆ ì‹¤í–‰
from main import main
main()
'''
    
    print(f"\n>> Running inference pipeline...")
    
    # CUDA í™˜ê²½ ë³€ìˆ˜ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
    env = os.environ.copy()
    env['CUDA_VISIBLE_DEVICES'] = env.get('CUDA_VISIBLE_DEVICES', '0')
    env['PYTHONUNBUFFERED'] = '1'
    
    # subprocessë¡œ ì‹¤í–‰
    process = subprocess.Popen(
        [INFERENCE_VENV_PYTHON, '-c', wrapper_script],
        cwd=INFERENCE_DIR,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True,
        env=env
    )
    
    # ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶œë ¥ í‘œì‹œ
    stdout_lines = []
    stderr_lines = []
    
    # stderrë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶œë ¥ (ì§„í–‰ ìƒí™©)
    for line in process.stderr:
        print(line, end='')
        stderr_lines.append(line)
    
    # stdout ì½ê¸°
    stdout, _ = process.communicate()
    stdout_lines.append(stdout)
    
    return_code = process.returncode
    
    # ì‹¬ë³¼ë¦­ ë§í¬ ì •ë¦¬
    if link_created and os.path.islink(inference_video_path):
        os.unlink(inference_video_path)
        print(f"   Removed symlink: {inference_video_path}")
    
    if return_code != 0:
        error_msg = ''.join(stderr_lines)
        raise RuntimeError(f"Inference pipeline failed (exit code {return_code}):\n{error_msg}")
    
    # =====================================================
    # Step 2: ê²°ê³¼ JSON ë¡œë“œ ë° ë³€í™˜
    # =====================================================
    stage3_path = os.path.join(output_dir, "stage3_final_narrative_refined.json")
    
    if not os.path.exists(stage3_path):
        # stage3ê°€ ì—†ìœ¼ë©´ stage2ë‚˜ stage1 ê²°ê³¼ ì‚¬ìš©
        for fallback in ["stage2_final_output.json", "stage1_narrative_output.json", "final_ad_creation_output.json"]:
            fallback_path = os.path.join(output_dir, fallback)
            if os.path.exists(fallback_path):
                stage3_path = fallback_path
                print(f"   Using fallback: {fallback}")
                break
    
    if not os.path.exists(stage3_path):
        raise FileNotFoundError(f"No output JSON found in {output_dir}")
    
    with open(stage3_path, 'r', encoding='utf-8') as f:
        stage3_data = json.load(f)
    
    print(f"\n>> Converting to TTS format...")
    tts_result = convert_to_tts_format(stage3_data, video_path, lang)
    
    # =====================================================
    # Step 3: ìµœì¢… JSON ì €ì¥
    # =====================================================
    if video_id:
        output_filename = f"{video_id}_{lang}.ad.json"
    else:
        video_basename_no_ext = os.path.splitext(os.path.basename(video_path))[0]
        output_filename = f"{video_basename_no_ext}_{lang}.ad.json"
    
    tts_output_path = os.path.join(output_dir, output_filename)
    
    with open(tts_output_path, 'w', encoding='utf-8') as f:
        json.dump(tts_result, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… Final TTS-compatible JSON saved to: {tts_output_path}")
    print(f"âœ… Total audio descriptions: {len(tts_result['audio_descriptions'])}")
    
    return tts_result, tts_output_path


def main():
    parser = argparse.ArgumentParser(description='Run inference pipeline for audio description generation')
    parser.add_argument('--video_path', type=str, required=True, help='Path to input video file')
    parser.add_argument('--output_dir', type=str, default=None, help='Output directory')
    parser.add_argument('--lang', type=str, default='en', choices=['en', 'ko'], help='Output language (en or ko)')
    parser.add_argument('--video_id', type=str, default=None, help='Video ID for output filename')
    parser.add_argument('--json_only', action='store_true', help='Output JSON result to stdout (for API integration)')
    
    args = parser.parse_args()
    
    try:
        result, output_path = run_inference_pipeline(
            video_path=args.video_path,
            output_dir=args.output_dir,
            lang=args.lang,
            video_id=args.video_id
        )
        
        if args.json_only:
            # API í†µí•©ì„ ìœ„í•´ JSONë§Œ stdoutìœ¼ë¡œ ì¶œë ¥
            print(json.dumps({
                'success': True,
                'output_path': output_path,
                'segments': [
                    {
                        'id': seg['id'],
                        'start': seg['start_time'],
                        'end': seg['end_time'],
                        'text': seg['description']
                    }
                    for seg in result['audio_descriptions']
                ]
            }))
        else:
            print("\n" + "="*50)
            print("ğŸ‰ Pipeline completed successfully!")
            print("="*50)
            
    except Exception as e:
        import traceback
        error_info = {
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }
        if args.json_only:
            print(json.dumps(error_info))
        else:
            print(f"\nâŒ Pipeline failed: {e}")
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

